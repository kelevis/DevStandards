# 机器学习基本概念及重要参数说明

# 基本概念

## Epoch、Batch、Iteration

Epoch（时期）：一个Epoch是指整个数据集的全部样本正向反向训练一次，通俗的讲Epoch的值就是整个数据集被训练的次数；

Batch（批次）：深度学习每一次参数的更新所需要损失函数并不是由一个数据获得的，而是由一组数据加权得到的，这一组数据就是一个批（Batch），每组数据的样本数量就是Batch Size；

Iteration（迭代）：训练的迭代次数，即执行Batch的次数，简单来说一个Iteration就是执行一次Batch Size样本；**Iteration在一些框架上通过num_steps进行设置**。

注：深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式：

- 第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。

- 另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。

为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。



**三个参数的关系**

Epoch = (Batch * Iteration) / 样本数

比如训练集有500个样本，batch_size = 10 ，那么训练完整个样本集：iteration=50，epoch=1





# 重要参数

## Learning Rate（学习率）

学习率（Learning Rate，LR。常用η表示）是一个超参数，考虑学习过程中的损失梯度（loss），它控制着我们在多大程度上调整网络的权重。

简单直白的说法：Learning Rate是调整神经网络输入权重的一种方法。如果感知机预测正确，则对应的输入权重不会变化，否则会根据Loss Function来对感知机重新调整，而这个调整的幅度大小就是Learning Rate，也就是在调整的基础上，增加一个比值。

如下图的权重w，在输出之后预测正确与否，若正确则保持权重w不变，若错误则用右边的公式来对权重w进行调整，如下图（0.001就是学习率的值）：

**new_weight= existing_weight — learning_rate * gradient (新权值 = 当前权值 – 学习率 × 梯度)**

![img](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/v2-d4563539367d5cfcc3ff749eb309d45a_1440w.jpg)



**学习率设置大小对训练的影响**

1、学习率值越低，沿着向下的斜率就越慢。虽然这可能是一个好主意（使用低学习率），以确保我们不会错过任何局部最小值；但也有可能意味着我们将耗费很久的时间来收敛——特别是当我们陷入平坦区（plateau region）的时候；

2、学习率值越高，权重调整的跨度就越大，意味着有可能更快速地收敛。但也有可能根本不会收敛，甚至会发散，因为权重的该变量可能会非常大，使得优化越过最小值，导致损失函数变得更糟。

简单直白的说法：一般Learning Rate的取值都在0.0001到0.01之间，这个效果就像你走路的步子，步子迈大了，很容易错过最佳点，而迈小了又需要花更长的时间才能到最佳点。



**学习率的设置参考**

在训练过程中，一般根据训练轮数设置动态变化的学习率。

- 刚开始训练时：学习率以 0.01 ~ 0.001 为宜。
- 一定轮数过后：逐渐减缓。
- 接近训练结束：学习速率的衰减应该在100倍以上。
- 学习率和网络的层数一般成反比，层数越多，学习率通常要减小。

注：

- 如果是从零开始训练，学习率可以设置为3、1、0.5、0.1、0.05、0.01、0.005，0.005、0.0001、0.00001具体需结合实际情况对比判断
- 如果是 **迁移学习** ，由于模型已在原始数据上收敛，此时应设置较小学习率 () 在新数据上进行 **微调** 。



**学习率减缓机制**

| 轮数减缓 | 指数减缓        | 分数减缓                         |                           |
| :------- | :-------------- | :------------------------------- | ------------------------- |
| 英文名   | step decay      | exponential decay                | decay                     |
| 方法     | 每N轮学习率减半 | 学习率按训练轮数增长指数插值递减 | 控制减缓幅度， 为训练轮数 |



**基于目标函数损失值（Loss）调整学习率**

理想情况下 **曲线** 应该是 **滑梯式下降** `[绿线]`： 

![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20180202222601241.jfif)

1. 曲线 **初始时 上扬** `[红线]`： 
   Solution：**初始** 学习率过大 导致 **振荡**，应减小学习率，并 **从头 开始训练** 。
2. 曲线 **初始时 强势下降 没多久 归于水平** `[紫线]`： 
   Solution：**后期** 学习率过大 导致 **无法拟合**，应减小学习率，并 **重新训练 后几轮** 。
3. 曲线 **全程缓慢** `[黄线]`： 
   Solution：**初始** 学习率过小 导致 **收敛慢**，应增大学习率，并 **从头 开始训练** 。



**训练中与Learning Rate相关的问题**

1、训练中如果出现loss为NaN的情况（例如：NaN loss during training tensorflow），可能与学习率设置过大，整个网络随机初始化，很容易出现Nan，这时候需要把学习率调小，可以尝试0.1，0.01，0.001，直到不出现Nan为止；



## Batch Size（一次训练样本数）

Batch Size用于设置一次训练所选取的样本数，其大小影响模型的优化程度和速度。

**设置合适的Batch Size有以下优点**

1、通过并行化提高内存的利用率。就是尽量让你的GPU满载运行，提高训练速度。
2、单个epoch的迭代次数减少了，参数的调整也慢了，假如要达到相同的识别精度，需要更多的epoch。
3、适当Batch Size使得梯度下降方向更加准确。



**Batch Size从小到大的变化对网络影响**

1、没有Batch Size，梯度准确，只适用于小样本数据库
2、Batch Size=1，梯度变来变去，非常不准确，网络很难收敛。
3、Batch Size增大，梯度变准确，
4、Batch Size增大，梯度已经非常准确，再增加Batch Size也没有用

注意：Batch Size增大了，要到达相同的准确度，必须要增大epoch。


**Batch Size与其他参数的设置关系**

1、Batch Size=1，每次计算一个样本，梯度不准确，这时候学习率Lr要降低；Batch Size设置较大时，一般学习率Lr要增大；



**训练中与Batch Size相关的问题**

1、如果训练中存在内存分配不足的问题（例如Tensorflow的memory_limit_错误），可能是由于Batch Size设置过大，显存不足导致出错，这时可以将Batch Size适当调小解决问题；

2、训练中如果出现loss为NaN的情况（例如：NaN loss during training tensorflow），可能是由于Batch Size设置过小（例如设置为1）导致梯度精度出现问题，可适当提高Batch Size的值看是否仍出现问题；



# 评价参数

在机器学习、数据挖掘、推荐系统完成建模之后，需要对模型的效果做评价。

业内目前常常采用的评价指标有准确率(Precision)、召回率(Recall)、F值(F-Measure)等，下图是不同机器学习算法的评价指标。下文讲对其中某些指标做简要介绍。

![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204103808)

**本文针对二元分类器！**
**本文针对二元分类器！！**
**本文针对二元分类器！！！**

**对分类的分类器的评价指标将在以后文章中介绍。**

**在介绍指标前必须先了解“混淆矩阵”：**

**混淆矩阵**

True Positive(真正，TP)：将正类预测为正类数

True Negative(真负，TN)：将负类预测为负类数

False Positive(假正，FP)：将负类预测为正类数误报 (Type I error)

False Negative(假负，FN)：将正类预测为负类数→漏报 (Type II error)

![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204227164)

![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204250714)

**1、准确率（Accuracy）**

准确率(accuracy)计算公式为：
![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204429418)

注：准确率是我们最常见的评价指标，而且很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好。
准确率确实是一个很好很直观的评价指标，但是有时候准确率高并不能代表一个算法就好。比如某个地区某天地震的预测，假设我们有一堆的特征作为地震分类的属性，类别只有两个：0：不发生地震、1：发生地震。一个不加思考的分类器，对每一个测试用例都将类别划分为0，那那么它就可能达到99%的准确率，但真的地震来临时，这个分类器毫无察觉，这个分类带来的损失是巨大的。为什么99%的准确率的分类器却不是我们想要的，因为这里数据分布不均衡，类别1的数据太少，完全错分类别1依然可以达到很高的准确率却忽视了我们关注的东西。再举个例子说明下。在正负样本不平衡的情况下，准确率这个评价指标有很大的缺陷。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用acc，即使全部预测成负类（不点击）acc也有 99% 以上，没有意义。因此，单纯靠准确率来评价一个算法模型是远远不够科学全面的。

**2、错误率（Error rate）**

错误率则与准确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(TP+TN+FP+FN)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 - error rate。

**3、灵敏度（sensitive）**

sensitive = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。

**4、特效度（sensitive）**

specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。

**5、精确率、精度（Precision）**

精确率(precision)定义为：
![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204550059)

表示被分为正例的示例中实际为正例的比例。

**6、召回率（recall）**

召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitive，可以看到召回率与灵敏度是一样的。

**7、综合评价指标（F-Measure）**
P和R指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。
F-Measure是Precision和Recall加权调和平均：
![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204659921)
当参数α=1时，就是最常见的F1，也即
![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170426204719124)
可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。

**8、其他评价指标**

计算速度：分类器训练和预测需要的时间；

鲁棒性：处理缺失值和异常值的能力；

可扩展性：处理大数据集的能力；

可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。

下面来看一下ROC和PR曲线（以下内容为自己总结）：

**1、ROC曲线：**
ROC（Receiver Operating Characteristic）曲线是以假正率（FP_rate）和假负率（TP_rate）为轴的曲线，ROC曲线下面的面积我们叫做AUC，如下图所示：

![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170612145321904)



图片根据Paper：Learning from eImbalanced Data画出


其中：![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170612152450659)
（1）曲线与FP_rate轴围成的面积（记作AUC）越大，说明性能越好，即图上L2曲线对应的性能优于曲线L1对应的性能。即：曲线越靠近A点（左上方）性能越好，曲线越靠近B点（右下方）曲线性能越差。
（2）A点是最完美的performance点，B处是性能最差点。
（3）位于C-D线上的点说明算法性能和random猜测是一样的–如C、D、E点。位于C-D之上（即曲线位于白色的三角形内）说明算法性能优于随机猜测–如G点，位于C-D之下（即曲线位于灰色的三角形内）说明算法性能差于随机猜测–如F点。
（4）虽然ROC曲线相比较于Precision和Recall等衡量指标更加合理，但是其在高不平衡数据条件下的的表现仍然过于理想，不能够很好的展示实际情况。

 

**2、PR曲线：**
即，PR（Precision-Recall）曲线。
举个例子（例子来自Paper：Learning from eImbalanced Data）：
假设N_c>>P_c（即Negative的数量远远大于Positive的数量），若FP很大，即有很多N的sample被预测为P，因为![这里写图片描述](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.assets/20170612153000354)，因此FP_rate的值仍然很小（如果利用ROC曲线则会判断其性能很好，但是实际上其性能并不好），但是如果利用PR，因为Precision综合考虑了TP和FP的值，因此在极度不平衡的数据下（Positive的样本较少），PR曲线可能比ROC曲线更实用。